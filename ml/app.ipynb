{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6921a7-f3c7-4b8d-80a7-db04287d2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.34:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# app.py (Flask Backend)\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Initialize NLTK and load stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load the IMDB dataset and model (same preprocessing steps as in the original code)\n",
    "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
    "train_data, test_data = dataset['train'], dataset['test']\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, tf.Tensor):\n",
    "        text_str = text.numpy().decode('utf-8')\n",
    "    else:\n",
    "        text_str = text\n",
    "    words = text_str.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Preprocess train data\n",
    "train_texts = [preprocess_text(text) for text, label in train_data]\n",
    "train_labels = [label.numpy() for text, label in train_data]\n",
    "\n",
    "# Train the TF-IDF vectorizer and logistic regression model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(train_texts)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, train_labels)\n",
    "\n",
    "# Sentiment prediction function\n",
    "def predict_sentiment(text):\n",
    "    text_processed = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([text_processed])\n",
    "    prediction = model.predict(text_tfidf)\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# API endpoint for sentiment analysis\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', None)\n",
    "    if text:\n",
    "        sentiment = predict_sentiment(text)\n",
    "        return jsonify({\"sentiment\": sentiment})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0e483-c37c-43fe-82e8-d4203bce4503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
